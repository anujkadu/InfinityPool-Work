{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1fKLJRQuCEdxVByr5e5h4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anujkadu/InfinityPool-Work/blob/main/Infinity_Pool_TensorFlow_Manual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Dataset (will default a loan)"
      ],
      "metadata": {
        "id": "s4UdHQG4J8t6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "CJvNI0OL0Hhx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Generate synthetic financial dataset\n",
        "np.random.seed(42)\n",
        "N = 1000\n",
        "df = pd.DataFrame({\n",
        "    'age': np.random.randint(21, 60, N),\n",
        "    'income': np.random.randint(20000, 150000, N),\n",
        "    'credit_score': np.random.randint(300, 900, N),\n",
        "    'loan_amount': np.random.randint(50000, 1000000, N),\n",
        "    'loan_term': np.random.choice([12, 24, 36, 48, 60], N),\n",
        "    'past_defaults': np.random.poisson(0.5, N)\n",
        "})\n",
        "df['will_default'] = (\n",
        "    (df['credit_score'] < 600).astype(int) |\n",
        "    ((df['loan_amount'] / df['income']) > 10).astype(int) |\n",
        "    (df['past_defaults'] > 2).astype(int)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Dataset (will post go viral?)"
      ],
      "metadata": {
        "id": "_JoPHESBPNy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert to tensorflow compatible format"
      ],
      "metadata": {
        "id": "-zT6Nc7HKA6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_raw = df.drop(\"will_default\", axis=1).values\n",
        "y = df[\"will_default\"].values\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X_raw)\n",
        "\n",
        "X_tensor = tf.constant(X, dtype=tf.float32)\n",
        "y_tensor = tf.constant(y.reshape(-1, 1), dtype=tf.float32)"
      ],
      "metadata": {
        "id": "ubZWZ06Q0QI3"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manually declare weights for each neuron of our model"
      ],
      "metadata": {
        "id": "tZ8muje8KE-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = tf.Variable([\n",
        "    [0.05, 0.1, 0.2, 0.0, 0.1, 0.3, 0.0, 0.15],\n",
        "    [0.0, 0.0, 0.1, 0.2, 0.0, 0.2, 0.1, 0.1],\n",
        "    [0.2, 0.2, 0.0, 0.1, 0.3, 0.0, 0.1, 0.0],\n",
        "    [0.1, 0.0, 0.0, 0.3, 0.1, 0.0, 0.2, 0.05],\n",
        "    [0.05, 0.1, 0.1, 0.1, 0.05, 0.1, 0.0, 0.0],\n",
        "    [0.3, 0.2, 0.1, 0.0, 0.0, 0.1, 0.3, 0.2]\n",
        "], dtype=tf.float32)\n",
        "b1 = tf.Variable([0.1, 0.2, 0.0, -0.1, 0.1, 0.0, 0.05, -0.05], dtype=tf.float32)\n",
        "\n",
        "# Second hidden layer (8 ‚Üí 4)\n",
        "W2 = tf.Variable([\n",
        "    [0.10, 0.20, 0.00, 0.10],\n",
        "    [0.00, 0.10, 0.20, 0.00],\n",
        "    [0.20, 0.10, 0.10, 0.00],\n",
        "    [0.10, 0.00, 0.00, 0.30],\n",
        "    [0.10, 0.00, 0.30, 0.10],\n",
        "    [0.00, 0.20, 0.10, 0.00],\n",
        "    [0.20, 0.10, 0.00, 0.10],\n",
        "    [0.00, 0.00, 0.10, 0.20]\n",
        "], dtype=tf.float32)\n",
        "b2 = tf.Variable([0.00, 0.10, -0.05, 0.20], dtype=tf.float32)\n",
        "\n",
        "# Output layer (4 ‚Üí 1)\n",
        "W3 = tf.Variable([[0.2], [0.1], [-0.1], [0.3]], dtype=tf.float32)\n",
        "b3 = tf.Variable([0.1], dtype=tf.float32)"
      ],
      "metadata": {
        "id": "JGsvxuMH0Twm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Declare optimizer and loss function"
      ],
      "metadata": {
        "id": "fXeDd8IEKL0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()"
      ],
      "metadata": {
        "id": "VQZflSd70W19"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate linear transformation and use activation function"
      ],
      "metadata": {
        "id": "ODTApj4YKRSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Z1 = tf.matmul(X_tensor, W1) + b1\n",
        "A1 = tf.nn.relu(Z1)\n",
        "\n",
        "Z2 = tf.matmul(A1, W2) + b2\n",
        "A2 = tf.nn.relu(Z2)\n",
        "\n",
        "Z3 = tf.matmul(A2, W3) + b3\n",
        "A3 = tf.nn.sigmoid(Z3)  # final output: probability\n",
        "\n",
        "print(\"üîπ Predicted Probabilities (first 5):\")\n",
        "print(A3.numpy()[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVZJxXc90dAY",
        "outputId": "dde63ef8-58c4-43a0-8d4b-1c4a9a86cbd4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Predicted Probabilities (first 5):\n",
            "[[0.57750833]\n",
            " [0.571759  ]\n",
            " [0.5744479 ]\n",
            " [0.5485885 ]\n",
            " [0.5649627 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate Loss and Accuracy before training"
      ],
      "metadata": {
        "id": "DR2IwrDeKcER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_fn(y_tensor, A3)\n",
        "y_pred_before = tf.cast(A3 > 0.5, dtype=tf.int32)\n",
        "y_true = tf.cast(y_tensor, dtype=tf.int32)\n",
        "accuracy_before = tf.reduce_mean(tf.cast(tf.equal(y_pred_before, y_true), tf.float32))\n",
        "\n",
        "print(f\"üéØ Loss: {loss.numpy():.4f}\")\n",
        "print(f\"üü° Accuracy Before Update: {accuracy_before.numpy() * 100:.4f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWA-iCYb0gHR",
        "outputId": "94a8f5de-f2c8-4607-f522-08d020f51263"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Loss: 0.6682\n",
            "üü° Accuracy Before Update: 63.8000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample prediction before training"
      ],
      "metadata": {
        "id": "-iPnWr7DKgQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_customer = pd.DataFrame([{\n",
        "    'age': 29,\n",
        "    'income': 25000,\n",
        "    'credit_score': 490,\n",
        "    'loan_amount': 450000,\n",
        "    'loan_term': 60,\n",
        "    'past_defaults': 3\n",
        "}])\n",
        "\n",
        "# Normalize\n",
        "new_customer_scaled = scaler.transform(new_customer)\n",
        "X_new = tf.constant(new_customer_scaled, dtype=tf.float32)\n",
        "\n",
        "# Manual forward pass BEFORE training\n",
        "Z1 = tf.matmul(X_new, W1) + b1\n",
        "A1 = tf.nn.relu(Z1)\n",
        "Z2 = tf.matmul(A1, W2) + b2\n",
        "A2 = tf.nn.relu(Z2)\n",
        "Z3 = tf.matmul(A2, W3) + b3\n",
        "A3 = tf.nn.sigmoid(Z3)\n",
        "\n",
        "print(\"üîç BEFORE Training ‚Üí Probability of default:\", A3.numpy()[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luHWLTON7bkQ",
        "outputId": "a565fb5e-91db-4a9b-e003-62800c6e6745"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç BEFORE Training ‚Üí Probability of default: 0.5693356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate Gradients"
      ],
      "metadata": {
        "id": "glg9UMJiKlgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf.matmul: matrix multiplication\n",
        "\n",
        "tf.nn.relu: zeroes out negatives (adds non-linearity)\n",
        "\n",
        "tf.nn.sigmoid: converts raw score into probability between 0 and 1"
      ],
      "metadata": {
        "id": "AiGJn7caThfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape() as tape:\n",
        "    Z1 = tf.matmul(X_tensor, W1) + b1\n",
        "    A1 = tf.nn.relu(Z1)\n",
        "    Z2 = tf.matmul(A1, W2) + b2\n",
        "    A2 = tf.nn.relu(Z2)\n",
        "    Z3 = tf.matmul(A2, W3) + b3\n",
        "    A3 = tf.nn.sigmoid(Z3)\n",
        "    loss = loss_fn(y_tensor, A3)\n",
        "\n",
        "# Compute gradients\n",
        "grads = tape.gradient(loss, [W1, b1, W2, b2, W3, b3])\n",
        "print(\"üîÑ Gradients calculated for all weights and biases.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW9M4Sul0lBs",
        "outputId": "b2560d32-ace6-4c35-c93c-b23cf9d0e873"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Gradients calculated for all weights and biases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Sample Epoch"
      ],
      "metadata": {
        "id": "iva_eXSOKuwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply gradients to update weights\n",
        "optimizer.apply_gradients(zip(grads, [W1, b1, W2, b2, W3, b3]))\n",
        "\n",
        "# Rerun forward pass to see new predictions\n",
        "Z1 = tf.matmul(X_tensor, W1) + b1\n",
        "A1 = tf.nn.relu(Z1)\n",
        "Z2 = tf.matmul(A1, W2) + b2\n",
        "A2 = tf.nn.relu(Z2)\n",
        "Z3 = tf.matmul(A2, W3) + b3\n",
        "A3 = tf.nn.sigmoid(Z3)\n",
        "\n",
        "# Accuracy after update\n",
        "y_pred = tf.cast(A3 > 0.5, dtype=tf.int32)\n",
        "y_true = tf.cast(y_tensor, dtype=tf.int32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred, y_true), tf.float32))\n",
        "\n",
        "print(\"‚úÖ Predicted Probabilities After Update (first 5):\")\n",
        "print(A3.numpy()[:5])\n",
        "print(f\"üéØ Accuracy After Update: {accuracy.numpy() * 100:.4f}%\")\n",
        "\n",
        "# Print updated weights\n",
        "print(\"\\nüîß Updated Weights:\")\n",
        "print(\"W1:\\n\", W1.numpy())\n",
        "print(\"W2:\\n\", W2.numpy())\n",
        "print(\"W3:\\n\", W3.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dntOkjrM0nA7",
        "outputId": "b4f4ceb0-f380-47e3-ef9c-aeefd7397b34"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Predicted Probabilities After Update (first 5):\n",
            "[[0.59297323]\n",
            " [0.58545554]\n",
            " [0.588917  ]\n",
            " [0.55651724]\n",
            " [0.5771877 ]]\n",
            "üéØ Accuracy After Update: 63.8000%\n",
            "\n",
            "üîß Updated Weights:\n",
            "W1:\n",
            " [[ 0.05998636  0.09009433  0.20997621  0.00999052  0.10995258  0.30990568\n",
            "   0.00998805  0.15998083]\n",
            " [-0.00918652  0.00617352  0.0913417   0.19029479 -0.00763409  0.19382648\n",
            "   0.09071912  0.09605084]\n",
            " [ 0.19000886  0.20993868 -0.00998455  0.09000558  0.2900308  -0.00993868\n",
            "   0.09000777 -0.00998722]\n",
            " [ 0.10999209 -0.00994529  0.00998621  0.30999494  0.10997254  0.00994529\n",
            "   0.20999308  0.05998865]\n",
            " [ 0.05998746  0.09008672  0.10997813  0.10999187  0.05995642  0.10991328\n",
            "   0.00998902  0.00998212]\n",
            " [ 0.30995333  0.19031757  0.10991862  0.00996951  0.00983862  0.10968243\n",
            "   0.3099591   0.20993479]]\n",
            "W2:\n",
            " [[ 0.10998223  0.20996459 -0.00996459  0.10998812]\n",
            " [ 0.00998752  0.10997514  0.19002485  0.00999166]\n",
            " [ 0.20998581  0.10997172  0.09002828  0.00999051]\n",
            " [ 0.10998176  0.00996365 -0.00996365  0.3099878 ]\n",
            " [ 0.10993839  0.0098776   0.29012242  0.10995882]\n",
            " [ 0.009989    0.2099781   0.09002191  0.00999264]\n",
            " [ 0.20998755  0.1099752  -0.00997519  0.10999168]\n",
            " [ 0.00997462  0.00994943  0.09005057  0.20998305]]\n",
            "W3:\n",
            " [[ 0.20999528]\n",
            " [ 0.10999788]\n",
            " [-0.09001072]\n",
            " [ 0.3099984 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running multiple epochs"
      ],
      "metadata": {
        "id": "z0jLg2XBMCyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "# Training loop\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Forward pass\n",
        "        Z1 = tf.matmul(X_tensor, W1) + b1\n",
        "        A1 = tf.nn.relu(Z1)\n",
        "        Z2 = tf.matmul(A1, W2) + b2\n",
        "        A2 = tf.nn.relu(Z2)\n",
        "        Z3 = tf.matmul(A2, W3) + b3\n",
        "        A3 = tf.nn.sigmoid(Z3)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(y_tensor, A3)\n",
        "\n",
        "    # Compute gradients\n",
        "    grads = tape.gradient(loss, [W1, b1, W2, b2, W3, b3])\n",
        "    # Update weights\n",
        "    optimizer.apply_gradients(zip(grads, [W1, b1, W2, b2, W3, b3]))\n",
        "\n",
        "    # Compute accuracy\n",
        "    y_pred = tf.cast(A3 > 0.5, dtype=tf.int32)\n",
        "    y_true = tf.cast(y_tensor, dtype=tf.int32)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred, y_true), tf.float32))\n",
        "\n",
        "    # Print progress every 10 epochs\n",
        "    if epoch % 10 == 0 or epoch == 1:\n",
        "        print(f\"üìò Epoch {epoch:03d} ‚Üí Loss: {loss.numpy():.4f} | Accuracy: {accuracy.numpy() * 100:.2f}%\")\n",
        "    # print(\"\\nüîß Updated Weights:\")\n",
        "    # print(\"W1:\\n\", W1.numpy())\n",
        "    # print(\"W2:\\n\", W2.numpy())\n",
        "    # print(\"W3:\\n\", W3.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CqH-xoL0pF-",
        "outputId": "55e10415-c938-44c1-9535-301d5d12cede"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìò Epoch 001 ‚Üí Loss: 0.6651 | Accuracy: 63.80%\n",
            "üìò Epoch 010 ‚Üí Loss: 0.6482 | Accuracy: 63.80%\n",
            "üìò Epoch 020 ‚Üí Loss: 0.6134 | Accuracy: 63.80%\n",
            "üìò Epoch 030 ‚Üí Loss: 0.5301 | Accuracy: 73.70%\n",
            "üìò Epoch 040 ‚Üí Loss: 0.4206 | Accuracy: 81.60%\n",
            "üìò Epoch 050 ‚Üí Loss: 0.3278 | Accuracy: 86.30%\n",
            "üìò Epoch 060 ‚Üí Loss: 0.2919 | Accuracy: 86.10%\n",
            "üìò Epoch 070 ‚Üí Loss: 0.2871 | Accuracy: 86.40%\n",
            "üìò Epoch 080 ‚Üí Loss: 0.2873 | Accuracy: 86.20%\n",
            "üìò Epoch 090 ‚Üí Loss: 0.2864 | Accuracy: 86.40%\n",
            "üìò Epoch 100 ‚Üí Loss: 0.2859 | Accuracy: 86.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction based on fine tuned model"
      ],
      "metadata": {
        "id": "Xo1oXKmzMF02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_customer = pd.DataFrame([{\n",
        "    'age': 29,\n",
        "    'income': 25000,\n",
        "    'credit_score': 490,\n",
        "    'loan_amount': 450000,\n",
        "    'loan_term': 60,\n",
        "    'past_defaults': 3\n",
        "}])\n",
        "\n",
        "# Normalize\n",
        "new_customer_scaled = scaler.transform(new_customer)\n",
        "X_new = tf.constant(new_customer_scaled, dtype=tf.float32)\n",
        "\n",
        "# Manual forward pass BEFORE training\n",
        "Z1 = tf.matmul(X_new, W1) + b1\n",
        "A1 = tf.nn.relu(Z1)\n",
        "Z2 = tf.matmul(A1, W2) + b2\n",
        "A2 = tf.nn.relu(Z2)\n",
        "Z3 = tf.matmul(A2, W3) + b3\n",
        "A3 = tf.nn.sigmoid(Z3)\n",
        "\n",
        "print(\"üîç BEFORE Training ‚Üí Probability of default:\", A3.numpy()[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swQpmjOq7l1T",
        "outputId": "48983498-4a97-49d9-a728-7d11838d71c5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç BEFORE Training ‚Üí Probability of default: 0.9992848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}